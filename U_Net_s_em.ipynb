{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IN-VVyPR4SlP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from source import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(x, height, width):\n",
    "        i_h, i_w = x.shape\n",
    "        p_h, p_w = (i_h-height)//2, (i_w-width)//2\n",
    "        return x[p_h:p_h+height, p_w:p_w+width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1qqQYJsabaN"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "\n",
    "class Ds(Dataset):\n",
    "    def __init__(self, root_dir, in_dir, label_dir, transform=None, target_transform=None, transforms=False, test=False):\n",
    "        '''\n",
    "        Args:\n",
    "          root_dir (string): Path to directory with images and labels\n",
    "          in_dir (string): Relative path to images (wrt root_dir)\n",
    "          label_dir (string): Relative path to labels (wrt root_dir)\n",
    "        '''\n",
    "        self.root_dir = root_dir\n",
    "        self.in_dir = in_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transforms = transforms\n",
    "        self.transform= transform\n",
    "        self.target_transform = target_transform\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        if(transforms):\n",
    "            return 23\n",
    "        elif(not test):\n",
    "            return 7\n",
    "        else:\n",
    "            return 30\n",
    "    \n",
    "    def common_transform(self, image, mask):\n",
    "        # Random Affine\n",
    "        ret = torchvision.transforms.RandomAffine.get_params((-0.1,0.1), [-0.01,0.01], None, None, image.size)\n",
    "        image = TF.affine(image, *ret, fillcolor=0)\n",
    "        mask = TF.affine(mask, *ret, fillcolor=0)                \n",
    "    \n",
    "        # Random horizontal flipping\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.hflip(image)\n",
    "            mask = TF.hflip(mask)\n",
    "\n",
    "        # Random vertical flipping\n",
    "        if random.random() > 0.5:\n",
    "            image = TF.vflip(image)\n",
    "            mask = TF.vflip(mask)\n",
    "            \n",
    "        # Transform to tensor\n",
    "        image = transforms.Pad(90,padding_mode='reflect')(image)\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "            \n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = \"t-\"+str(idx)+\".tif\"\n",
    "        label_name = \"l-\"+str(idx)+\".tif\"\n",
    "        img_loc = os.path.join(self.root_dir, self.in_dir, img_name)\n",
    "        label_loc = os.path.join(self.root_dir, self.label_dir, label_name)\n",
    "        image=Image.open(img_loc).convert(\"RGB\")\n",
    "        label=Image.open(label_loc)\n",
    "        if self.transform:\n",
    "            image=self.transform(image)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label=self.target_transform(label)\n",
    "            \n",
    "        if self.transforms:\n",
    "            tf = self.transforms\n",
    "            image, label = self.common_transform(image, label)\n",
    "        else:\n",
    "            image = transforms.Pad(90,padding_mode='reflect')(image)\n",
    "            image = TF.to_tensor(image)\n",
    "            label = TF.to_tensor(label)\n",
    "            \n",
    "        label=torchvision.transforms.Lambda(transforms.Lambda(lambda x:(x>0).long()))(label)\n",
    "\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "x_transform = transforms.Compose([transforms.Grayscale(1),\n",
    "                                  transforms.Resize((392,392)),\n",
    "                                  ])\n",
    "\n",
    "y_transform = transforms.Compose([transforms.Grayscale(1),\n",
    "                                  transforms.Resize((388,388)),\n",
    "                                  ])\n",
    "\n",
    "trainset = Ds(\"../em_stack/\",\"train\",\"labels\",x_transform, y_transform,True)\n",
    "valset = Ds(\"../em_stack/\",\"val\",\"val-labels\",x_transform, y_transform,False,False)\n",
    "testset = Ds(\"../em_stack/\",\"test\",\"labels\",x_transform, y_transform,False,True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size=3,shuffle=True,num_workers=8)\n",
    "valloader = torch.utils.data.DataLoader(valset,batch_size=3,shuffle=True,num_workers=8)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=3,shuffle=True,num_workers=8)\n",
    "dataiter=iter(trainloader)\n",
    "i,l = dataiter.__next__()\n",
    "print(i.shape)\n",
    "print(l.shape)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(i.numpy()[0][0], cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(l.numpy()[0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GasM4miT6Lue"
   },
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self, in_channels=1):\n",
    "#         super(Net, self).__init__()\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.conv1 = nn.Conv2d(in_channels, 64, 3, 1, 0)\n",
    "#         self.conv2 = nn.Conv2d(64, 64, 3, 1, 0)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.conv3 = nn.Conv2d(64, 128, 3, 1, 0)\n",
    "#         self.conv4 = nn.Conv2d(128, 128, 3, 1, 0)\n",
    "#         self.conv5 = nn.Conv2d(128, 256, 3, 1, 0)\n",
    "#         self.conv6 = nn.Conv2d(256, 256, 3, 1, 0)\n",
    "#         self.conv7 = nn.Conv2d(256, 512, 3, 1, 0)\n",
    "#         self.conv8 = nn.Conv2d(512, 512, 3, 1, 0)\n",
    "#         self.conv9 = nn.Conv2d(512, 1024, 3, 1, 0)\n",
    "#         self.conv10 = nn.Conv2d(1024, 1024, 3, 1, 0)\n",
    "#         self.upconv1 = nn.ConvTranspose2d(1024, 512, 2, 2)\n",
    "#         self.conv11 = nn.Conv2d(1024, 512, 3, 1, 0)\n",
    "#         self.conv12 = nn.Conv2d(512, 512, 3, 1, 0)\n",
    "#         self.upconv2 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
    "#         self.conv13 = nn.Conv2d(512, 256, 3, 1, 0)\n",
    "#         self.conv14 = nn.Conv2d(256, 256, 3, 1, 0)\n",
    "#         self.upconv3 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
    "#         self.conv15 = nn.Conv2d(256, 128, 3, 1, 0)\n",
    "#         self.conv16 = nn.Conv2d(128, 128, 3, 1, 0)\n",
    "#         self.upconv4 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
    "#         self.conv17 = nn.Conv2d(128, 64, 3, 1, 0)\n",
    "#         self.conv18 = nn.Conv2d(64, 64, 3, 1, 0)\n",
    "#         self.conv19 = nn.Conv2d(64, 2, 1, 1, 0)\n",
    "\n",
    "#     def center_crop(self, x, height, width):\n",
    "#         _, _, i_h, i_w = x.shape\n",
    "#         p_h, p_w = (i_h-height)//2, (i_w-width)//2\n",
    "#         return x[:, :, p_h:p_h+height, p_w:p_w+width]\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.relu(x)\n",
    "#         x1 = self.center_crop(x, 392, 392)\n",
    "#         x = self.pool(x)\n",
    "#         x = self.conv3(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv4(x)\n",
    "#         x = self.relu(x)\n",
    "#         x2 = self.center_crop(x, 200, 200)\n",
    "#         x = self.pool(x)\n",
    "#         x = self.conv5(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv6(x)\n",
    "#         x = self.relu(x)\n",
    "#         x3 = self.center_crop(x, 104, 104)\n",
    "#         x = self.pool(x)\n",
    "#         x = self.conv7(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv8(x)\n",
    "#         x = self.relu(x)\n",
    "#         x4 = self.center_crop(x, 56, 56)\n",
    "#         x = self.pool(x)\n",
    "#         x = self.conv9(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv10(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.upconv1(x)\n",
    "#         x = torch.cat((x4, x), dim=1)\n",
    "#         x = self.conv11(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv12(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.upconv2(x)\n",
    "#         x = torch.cat((x3, x), dim=1)\n",
    "#         x = self.conv13(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv14(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.upconv3(x)\n",
    "#         x = torch.cat((x2, x), dim=1)\n",
    "#         x = self.conv15(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv16(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.upconv4(x)\n",
    "#         x = torch.cat((x1, x), dim=1)\n",
    "#         x = self.conv17(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv18(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.conv19(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class downBlock(nn.Module):\n",
    "    '''\n",
    "    Conv2d --> ReLU --> Conv2d --> ReLU\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(downBlock, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 0),\n",
    "            nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 0),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        op = self.conv1(x)\n",
    "        op = self.conv2(op)\n",
    "        return op\n",
    "    \n",
    "class upBlock(nn.Module):\n",
    "    '''\n",
    "    x --> UpConv \\\n",
    "                --> cat --> Conv2d --> ReLU --> Conv2d --> ReLU   \n",
    "    skip -> Crop /\n",
    "    '''\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(upBlock, self).__init__()\n",
    "\n",
    "        self.conv = downBlock(in_channels, out_channels)\n",
    "        self.upConv = nn.ConvTranspose2d(in_channels, out_channels, 2, 2)\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        op2 = self.upConv(x)\n",
    "        pad = (op2.size()[2] - skip.size()[2]) // 2\n",
    "        op1 = F.pad(skip, [pad,pad,pad,pad])\n",
    "        inp = torch.cat([op1, op2], 1)\n",
    "        return self.conv(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=2):\n",
    "        super(Net, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        channels=[64,128,256,512,1024]\n",
    "\n",
    "        self.conv1 = downBlock(self.in_channels, channels[0])\n",
    "        self.pool1 = nn.MaxPool2d(2,2) \n",
    "        self.conv2 = downBlock(channels[0], channels[1])\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.conv3 = downBlock(channels[1], channels[2])\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\n",
    "        self.conv4 = downBlock(channels[2], channels[3])\n",
    "        self.pool4 = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.conv5 = downBlock(channels[3], channels[4])\n",
    "\n",
    "        self.up1 = upBlock(channels[4], channels[3])\n",
    "        self.up2 = upBlock(channels[3], channels[2])\n",
    "        self.up3 = upBlock(channels[2], channels[1])\n",
    "        self.up4 = upBlock(channels[1], channels[0])\n",
    "\n",
    "        self.conv6 = nn.Conv2d(channels[0], out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)                       # ||| ---> x1\n",
    "        x2 = self.conv2(self.pool1(x1))          #   ||| ---> x2\n",
    "        x3 = self.conv3(self.pool2(x2))          #     ||| ---> x3\n",
    "        x4 = self.conv4(self.pool3(x3))          #       ||| ---> x4\n",
    "        x5 = self.conv5(self.pool4(x4))          #         ||| = x5\n",
    "        x6 = self.up1(x5, x4)                    #\n",
    "        x7 = self.up2(x6, x3)\n",
    "        x8 = self.up3(x7, x2)\n",
    "        x9 = self.up4(x8, x1)\n",
    "        op = self.conv6(x9)\n",
    "        return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self, type='cross_entropy', weight=None):\n",
    "        super(Loss, self).__init__()\n",
    "        self.type = type\n",
    "        self.weight = weight\n",
    "        self.losses = []\n",
    "        self.dice_class_scores = []\n",
    "\n",
    "    def cross_entropy2d(self, logits, target):\n",
    "        c = logits.shape[1]\n",
    "        logits = logits.transpose(1, 2).transpose(2, 3).contiguous().view(-1, c)\n",
    "        target = target.view(-1) \n",
    "        loss = F.cross_entropy(logits, target, self.weight)\n",
    "        return loss\n",
    "    \n",
    "    def softDiceLoss(self, logits, targets):\n",
    "        \n",
    "        smooth = 1\n",
    "        num = targets.size(0)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        m1 = probs.view(num, -1).float()\n",
    "        m2 = targets.view(num, -1).float()\n",
    "        intersection = (m1 * m2)\n",
    "        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "        score = 1-score.sum() / num\n",
    "        return score\n",
    "#         smooth = 0.01\n",
    "#         num = targets.size(0)\n",
    "#         probs = torch.sigmoid(logits)\n",
    "#         m1 = probs.view(num, -1)\n",
    "#         target= nn.functional.one_hot(target)\n",
    "#         m2 = target.view(num, -1)\n",
    "#         intersection = (m1 * m2)\n",
    "#         score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "#         score = 1 - score.sum() / num\n",
    "#         return score\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         smooth = 0.01\n",
    "#         b_sz = logits.shape[0]\n",
    "#         c = logits.shape[1]\n",
    "#         logits = logits.transpose(1,2).transpose(2,3).contiguous().view(-1,c)\n",
    "#         target = target.view(-1)\n",
    "#         oneHot = nn.functional.one_hot(target)\n",
    "#         print(logits.shape)\n",
    "#         m1 = F.softmax(logits,dim=1)\n",
    "#         print(m1.shape)\n",
    "#         m2 = oneHot.view(-1,c).float()\n",
    "#         print(m2.shape)\n",
    "#         intersection = (m1 * m2)\n",
    "#         score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "#         class_score = 1 - score\n",
    "#         self.dice_class_scores = [self.dice_class_scores, class_score]\n",
    "#         score =-(score*self.weight).sum() / ((self.weight.sum())*b_sz)\n",
    "#         return score\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        if self.type=='cross_entropy':\n",
    "            loss = self.cross_entropy2d(logits, target)\n",
    "        elif self.type=='dice':\n",
    "            loss = self.softDiceLoss(logits, target)\n",
    "        self.losses = [self.losses, loss.item()]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4Otgg6Dx6iNH",
    "outputId": "be054d55-af6d-4c5e-99be-014ebefb1a64"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "net = Net()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "#     net=nn.DataParallel(net)\n",
    "    \n",
    "net = net.to(device)\n",
    "criterion = Loss(type=\"cross_entropy\",weight=torch.Tensor((6,1)).to(device))\n",
    "optimizer = optim.Adam(net.parameters(), weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softDiceLoss(logits, targets):\n",
    "\n",
    "    smooth = 1\n",
    "    num = targets.size(0)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    m1 = probs.view(num, -1).float()\n",
    "    m2 = targets.view(num, -1).float()\n",
    "    intersection = (m1 * m2)\n",
    "    score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "    score = 1-score.sum() / num\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../em_stack/model59.pth')\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n,l = dataiter.next()\n",
    "n,l = n.to(device), l.to(device)\n",
    "x=(l.reshape(-1)==0).sum().item()\n",
    "y=(l.reshape(-1)==1).sum().item()\n",
    "print((x+y)/x)\n",
    "print((x+y)/y)\n",
    "print(nn.functional.one_hot(l[0][0]).shape)\n",
    "plt.imshow(nn.functional.one_hot(l[0][0])[:,:,1].detach().cpu().numpy())\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(n[0][0].cpu().numpy(), cmap='gray')\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(l[0][0].cpu().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nRPuIdOTjx8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "loss_arr=[]\n",
    "\n",
    "for epoch in range(60):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(images)\n",
    "#         loss = criterion(outputs.permute(0,2,3,1).reshape(-1,2),labels.permute(0,2,3,1).reshape(-1))\n",
    "        loss=criterion(outputs,labels)\n",
    "#         loss_arr = [loss_arr, loss]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loss_arr.append(loss.item())\n",
    "\n",
    "        if epoch%10 == 9:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                (epoch + 1, i + 1, running_loss / 10))\n",
    "            ops = net(n)\n",
    "            fore = ops[0][0].cpu().detach().numpy()\n",
    "            back = ops[0][1].cpu().detach().numpy()\n",
    "            print(np.max(fore))\n",
    "            print(np.min(fore))\n",
    "            print(np.max(back))\n",
    "            print(np.min(back))\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(fore, cmap='gray')\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(back, cmap='gray')\n",
    "            plt.show()\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                }, \"../em_stack/model\"+str(epoch)+\".pth\")\n",
    "            running_loss = 0.0\n",
    "plt.plot(loss_arr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_arr)\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.title('Loss v/s batch')\n",
    "plt.savefig('CellLoss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_loss(labels, outputs, eps=1e-7):\n",
    "    \"\"\"Computes the Jaccard loss, a.k.a the IoU loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the jaccard loss so we\n",
    "    return the negated jaccard loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, H, W] or [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        jacc_loss: the Jaccard loss.\n",
    "    \"\"\"\n",
    "    outputs=outputs.argmax(dim=1,keepdim=True).reshape(-1)\n",
    "#     outputs = outputs[:,1,:,:].reshape(-1)>thresh\n",
    "    labels=labels.reshape(-1)\n",
    "    backf=(labels==0).sum().item()\n",
    "    foref=(labels==1).sum().item()\n",
    "    foref=(foref+backf)/foref\n",
    "    backf=(foref+backf)/backf\n",
    "#     outputs[outputs==1]*=foref\n",
    "#     outputs[outputs==0]*=backf\n",
    "#     labels[labels==1]*=foref\n",
    "#     labels[labels==0]*=backf\n",
    "    \n",
    "\n",
    "    return jaccard_score(labels,outputs.detach().cpu(),\"weighted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_loss = 0\n",
    "num_batches=0\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:\n",
    "        image, labels = data\n",
    "        images = image.to(device)\n",
    "        outputs = net(images)\n",
    "        iou_loss += jaccard_loss(labels, outputs)\n",
    "        num_batches+=1\n",
    "        for i in range(0,outputs.shape[0],6):\n",
    "#             plt.subplot(1,3,1)\n",
    "#             plt.imshow(center_crop(image[i][0],388,388), cmap='gray')\n",
    "#             plt.subplot(1,3,2)\n",
    "#             plt.imshow(outputs.argmax(dim=1,keepdim=True)[i][0].detach().cpu().numpy(), cmap='gray')\n",
    "#             plt.subplot(1,3,3)\n",
    "#             plt.imshow(labels.numpy()[i][0], cmap='gray')\n",
    "#             plt.show()\n",
    "            plt.imshow(center_crop(image[i][0],388,388), cmap='gray')\n",
    "            plt.show()\n",
    "#             plt.subplot(1,3,2)\n",
    "            plt.imshow(outputs.argmax(dim=1,keepdim=True)[i][0].detach().cpu().numpy(), cmap='gray')\n",
    "            plt.show()\n",
    "#             plt.subplot(1,3,3)\n",
    "            plt.imshow(labels.numpy()[i][0], cmap='gray')\n",
    "            plt.show()\n",
    "    iou_loss/=num_batches\n",
    "\n",
    "print(\"iou_loss = \",iou_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in testloader:\n",
    "        image, labels = data\n",
    "        images = image.to(device)\n",
    "        outputs = net(images)\n",
    "        for i in range(0,outputs.shape[0],6):\n",
    "            plt.subplot(1,3,1)\n",
    "            plt.imshow(center_crop(image[i][0],388,388), cmap='gray')\n",
    "            plt.subplot(1,3,2)\n",
    "            plt.imshow(outputs.argmax(dim=1,keepdim=True)[i][0].detach().cpu().numpy(), cmap='gray')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "U-Net.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
